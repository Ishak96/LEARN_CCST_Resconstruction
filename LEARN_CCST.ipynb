{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bm9XFDen-u96",
   "metadata": {
    "id": "bm9XFDen-u96"
   },
   "source": [
    "# **Setup the environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qk7e5hQuxgy5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qk7e5hQuxgy5",
    "outputId": "da7f9bdc-8e25-473b-f8c3-7e3a6703d85d"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cf0c6c",
   "metadata": {
    "id": "84cf0c6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/pytorch-gpu-1.11.0+py3.9.12/lib/python3.9/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n",
      "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/pytorch-gpu-1.11.0+py3.9.12/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Callback, Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from kornia.losses import ssim_loss, psnr_loss\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2GKtoiE8-cIf",
   "metadata": {
    "id": "2GKtoiE8-cIf"
   },
   "outputs": [],
   "source": [
    "USE_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0GeKFqiSWnrT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GeKFqiSWnrT",
    "outputId": "f0dfb924-b80f-466a-bbac-0a98675c0f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Available GPUs:  4\n",
      "Num Available workerss :  48\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = max(0, torch.cuda.device_count())\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = int(os.cpu_count())\n",
    "\n",
    "# Image size that we are going to use\n",
    "IMG_SIZE = 256\n",
    "\n",
    "N_THETA = 180\n",
    "N_RHO = ceil(IMG_SIZE*sqrt(2))\n",
    "NB_PROJECTIONS = N_THETA * N_RHO\n",
    "\n",
    "# Our images are graysacle (1 channels)\n",
    "N_CHANNELS = 1\n",
    "\n",
    "N_ITER = 20\n",
    "\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"models/LQNM_RNN/\")\n",
    "SAVE_NAME = \"LQNM_RNN_%i\" % IMG_SIZE + \"_N_ITER_%i\" % N_ITER +\"/\"\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_PATH, SAVE_NAME)\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    os.makedirs(CHECKPOINT_PATH)\n",
    "\n",
    "SAVE_VALID = \"Results/validation/%i\" % N_ITER + \"_ITER\" + \"/\"\n",
    "SAVE_TEST = \"Results/test/LQNM_RNN_%i\" % IMG_SIZE + \"_N_ITER_%i\" % N_ITER +\"/\"\n",
    "\n",
    "RESNET18_MODEL_PATH = \"models/resnet18.pth\"\n",
    "\n",
    "PATH_DATASETS = \"Lung-CT-sinogram-data-lack-%i\" % IMG_SIZE + \".npy\"\n",
    "PATH_SYSTEM_MATRIX = \"System_matrix_%i\" % IMG_SIZE + \".npy\"\n",
    "\n",
    "print(\"Num Available GPUs: \", AVAIL_GPUS)\n",
    "print(\"Num Available workerss : \", NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mAB9EP8BW8Mf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAB9EP8BW8Mf",
    "outputId": "f9836d0c-fea6-497a-f877-c893d75acf28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set file :  data/Lung-CT-sinogram-data-lack-256.npy\n",
      "System matrix file :  data/System_matrix_256.npy\n"
     ]
    }
   ],
   "source": [
    "if USE_COLAB: \n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    PATH_DATASETS = \"gdrive/MyDrive/\" + PATH_DATASETS\n",
    "    PATH_SYSTEM_MATRIX = \"gdrive/MyDrive/\" + PATH_SYSTEM_MATRIX\n",
    "    GIF_TEST = \"gdrive/MyDrive/\" + GIF_TEST\n",
    "else:\n",
    "    PATH_DATASETS = \"data/\" + PATH_DATASETS\n",
    "    PATH_SYSTEM_MATRIX = \"data/\" + PATH_SYSTEM_MATRIX\n",
    "\n",
    "print(\"Data set file : \", PATH_DATASETS)\n",
    "print(\"System matrix file : \", PATH_SYSTEM_MATRIX) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yzCE7RNY7QXd",
   "metadata": {
    "id": "yzCE7RNY7QXd"
   },
   "source": [
    "# **Utility function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "LuXtDDP_7V3m",
   "metadata": {
    "id": "LuXtDDP_7V3m"
   },
   "outputs": [],
   "source": [
    "def display_func(display_list, save=False, epoch=0):\n",
    "    plt.figure(figsize=(25, 25))\n",
    "    \n",
    "    theta = torch.squeeze(display_list[0]).cpu().numpy()\n",
    "    step = torch.squeeze(display_list[1]).cpu().numpy()\n",
    "\n",
    "    input_title=\"Input Sinogram : \" +str(theta)+\" Angle range projection, \"+str(step)+\" Step projection\"\n",
    "    predicted=\"Predicted Object\"\n",
    "\n",
    "    if len(display_list) > 4 :\n",
    "        psnr_p = -psnr_loss(display_list[3].cpu(), display_list[4].cpu(), 1)\n",
    "        ssim_p = -2 * ssim_loss(display_list[3].cpu(), display_list[4].cpu(), 5) + 1\n",
    "        predicted = predicted + \", PSNR=\" + str('%.2f' % psnr_p) + \", SSIM=\" + str('%.2f' % ssim_p)\n",
    "\n",
    "    title = [input_title, 'True Mask', predicted]\n",
    "\n",
    "    for i in range(2,len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i-2])\n",
    "        plt.imshow(torch.squeeze(display_list[i]).cpu().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    if save:\n",
    "        r_im = torch.squeeze(display_list[4].cpu())\n",
    "        save_image(r_im, SAVE_VALID + \"epoch_\" + str(epoch) + \"_angle=\"+str(theta)+\"_step=\"+str(step)+\"_psnr=\"+str(psnr_p.numpy())+\"_ssim=\"+str(ssim_p.numpy())+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oC9qOkme6hZq",
   "metadata": {
    "id": "oC9qOkme6hZq"
   },
   "source": [
    "# **Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JfS1j17aIQ0c",
   "metadata": {
    "id": "JfS1j17aIQ0c"
   },
   "outputs": [],
   "source": [
    "# load the numpy data array\n",
    "with open(PATH_DATASETS, 'rb') as f:\n",
    "    X_dataset = np.load(f)\n",
    "    Y_dataset = np.load(f)\n",
    "    angles_dataset = np.load(f)\n",
    "    steps_dataset = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mMNdrcUe72cF",
   "metadata": {
    "id": "mMNdrcUe72cF"
   },
   "outputs": [],
   "source": [
    "DATASET_SIZE = len(X_dataset)\n",
    "\n",
    "train_size = int(0.95 * DATASET_SIZE)\n",
    "val_size = DATASET_SIZE - train_size\n",
    "\n",
    "tensor_x = torch.Tensor(X_dataset)\n",
    "tensor_y = torch.Tensor(Y_dataset)\n",
    "tensor_angle = torch.Tensor(angles_dataset)\n",
    "tensor_step = torch.Tensor(steps_dataset)\n",
    "\n",
    "dataset = TensorDataset(tensor_x, tensor_y, tensor_angle, tensor_step) # create your datset\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_set = DataLoader(train_set)\n",
    "val_set = DataLoader(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afZKDUGC_5fq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afZKDUGC_5fq",
    "outputId": "4d948f8a-b611-4e1f-ba28-b2b1b5da190a"
   },
   "outputs": [],
   "source": [
    "print(\"Size all dataset: \", len(dataset))\n",
    "print(\"Size training dataset: \", len(train_set))\n",
    "print(\"Size testing dataset: \", len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WVydp5UGxHOC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "WVydp5UGxHOC",
    "outputId": "51675b1f-7e2c-4f09-c9d8-25ec94727391"
   },
   "outputs": [],
   "source": [
    "inp, re, angle, step = next(iter(train_set))\n",
    "display_func([angle, step, inp, re, re], save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "m6qG9Ze0V5dO",
   "metadata": {
    "id": "m6qG9Ze0V5dO"
   },
   "outputs": [],
   "source": [
    "class CTDataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir: str = PATH_DATASETS, batch_size: int = BATCH_SIZE, num_workers: int = NUM_WORKERS):\n",
    "        super(CTDataModule, self).__init__()\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "      # download\n",
    "      # load the numpy data array\n",
    "        print(\"BEGIN__Loading the dataset__\")\n",
    "        with open(self.data_dir, 'rb') as f:\n",
    "            X_dataset = torch.Tensor(np.load(f))\n",
    "            Y_dataset = torch.Tensor(np.load(f))\n",
    "            angles_dataset = torch.Tensor(np.load(f))\n",
    "            steps_dataset = torch.Tensor(np.load(f))\n",
    "        print(\"__DONE__Loading the dataset__\")\n",
    "\n",
    "        self.dataset = TensorDataset(X_dataset, Y_dataset, angles_dataset, steps_dataset) # create the datset\n",
    "      \n",
    "        self.dataset_size = len(self.dataset)\n",
    "        self.train_size = int(0.95 * self.dataset_size)\n",
    "        self.val_size = int(0.75 * (self.dataset_size - self.train_size))\n",
    "        self.test_size = self.dataset_size - (self.train_size + self.val_size)\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "      # Assign train/val datasets\n",
    "      if stage == \"fit\" or stage is None:\n",
    "            self.train_set, self.val_set, _ = random_split(self.dataset, [self.train_size, self.val_size, self.test_size])\n",
    "\n",
    "      # Assign test dataset\n",
    "      if stage == \"test\" or stage is None:\n",
    "            _, _, self.test_set = random_split(self.dataset, [self.train_size, self.val_size, self.test_size])\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j-rUxyQwUY0i",
   "metadata": {
    "id": "j-rUxyQwUY0i"
   },
   "source": [
    "# **Build the QNMs-RNN model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gm872NWtUkT7",
   "metadata": {
    "id": "gm872NWtUkT7"
   },
   "source": [
    "## QNMs-RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5MdimIJsvT5",
   "metadata": {
    "id": "d5MdimIJsvT5"
   },
   "outputs": [],
   "source": [
    "class RegularizationBlock(nn.Module):\n",
    "    def __init__(self, in_channels=1, filters=48):\n",
    "        super(RegularizationBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=5, padding='same')   \n",
    "        self.conv2 = nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=5, padding='same')\n",
    "        self.outputconv = nn.Conv2d(in_channels=filters, out_channels=in_channels, kernel_size=5, padding='same')\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, x_t):\n",
    "        x = self.relu(self.conv1(x_t))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x_out = self.outputconv(x)\n",
    "\n",
    "        return torch.squeeze(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jh72OpY4la-d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "jh72OpY4la-d",
    "outputId": "5e0ccde6-0ce1-4326-80d3-f511b7fe9bd8"
   },
   "outputs": [],
   "source": [
    "reg_block = RegularizationBlock()\n",
    "x_reg = reg_block(re)\n",
    "plt.imshow(np.squeeze(x_reg.detach()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "NL0JCn4rs6HC",
   "metadata": {
    "id": "NL0JCn4rs6HC"
   },
   "outputs": [],
   "source": [
    "class QNM_RNNCell(nn.Module):\n",
    "    def __init__(self, N, N_THETA, N_RHO):\n",
    "        super(QNM_RNNCell, self).__init__()\n",
    "        \n",
    "        self.N = N\n",
    "        self.N_THETA = N_THETA\n",
    "        self.N_RHO = N_RHO\n",
    "\n",
    "        self.reg_block = RegularizationBlock().cuda()\n",
    "        self.h_linear = nn.Linear(in_features=self.N, out_features=self.N).cuda()\n",
    "        self.lamb = nn.Parameter(torch.tensor(1.))\n",
    "\n",
    "        self.splus = nn.Softplus()\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "        self.apply(self.__init_weights__)\n",
    "\n",
    "\n",
    "    def __init_weights__(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    \n",
    "    def scale_tensor(self, X, a=0, b=1):\n",
    "        x_min = torch.min(X)\n",
    "        x_max = torch.max(X)\n",
    "        q = (X - x_min)*(b-a)\n",
    "        d = x_max - x_min\n",
    "        \n",
    "        if d != 0:\n",
    "            s_X = q / d\n",
    "        else:\n",
    "            s_X = X\n",
    "        return s_X\n",
    "\n",
    "\n",
    "    def compute_next_H_t(self, H_t, s_t, z_t):\n",
    "        s_t = self.scale_tensor(s_t)\n",
    "        z_t = self.scale_tensor(z_t)\n",
    "\n",
    "        diag_next_H_t = self.splus(self.h_linear(torch.diagonal(H_t, 0)))\n",
    "        next_H_t = torch.diag(diag_next_H_t)\n",
    "        \n",
    "        h_t_loss = self.mse_loss(next_H_t, H_t) + self.mse_loss(next_H_t @ z_t, s_t)\n",
    "        return next_H_t, h_t_loss\n",
    "\n",
    "    \n",
    "    def forward(self, As, x_t, y, H_t, sigmaE_t):        \n",
    "        AsT = torch.transpose(As, 0, 1)\n",
    "\n",
    "        '''compute the regularization terms'''\n",
    "        x_reg = self.reg_block(x_t)\n",
    "\n",
    "        '''compute next sigmaE_t'''\n",
    "        x_t = torch.reshape(x_t, (self.N*self.N, ))\n",
    "        y_t = torch.sparse.mm(As, x_t[:, None])\n",
    "        y_t = self.scale_tensor(torch.squeeze(y_t))\n",
    "        \n",
    "        y_dif = y_t - y\n",
    "        y_dif = self.scale_tensor(y_dif)\n",
    "        \n",
    "        x_update_t = torch.sparse.mm(AsT, y_dif[:, None])\n",
    "        x_update_t = torch.squeeze(x_update_t)\n",
    "        x_update_t = torch.reshape(x_update_t, (self.N, self.N))\n",
    "        \n",
    "        next_sigmaE_t = -self.lamb * (x_update_t + x_reg)\n",
    "        \n",
    "        '''compute delta_x'''\n",
    "        delta_x_t = H_t @ next_sigmaE_t\n",
    "        delta_x_t = self.scale_tensor(delta_x_t)\n",
    "\n",
    "        '''compute next x'''\n",
    "        x_t = torch.reshape(torch.squeeze(x_t), (self.N, self.N))\n",
    "        next_x_t = x_t + delta_x_t\n",
    "        next_x_t = self.scale_tensor(next_x_t)\n",
    "\n",
    "        '''compute next H'''\n",
    "        s_t = next_x_t - x_t\n",
    "        z_t = next_sigmaE_t - sigmaE_t \n",
    "\n",
    "        next_H_t, h_t_loss = self.compute_next_H_t(H_t, s_t, z_t)\n",
    "        \n",
    "        next_x_t = next_x_t[None, None, :, :]\n",
    "        return next_x_t, next_H_t, next_sigmaE_t, h_t_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tN-qqzp8tQEy",
   "metadata": {
    "id": "tN-qqzp8tQEy"
   },
   "outputs": [],
   "source": [
    "class QNM_RNN(nn.Module):\n",
    "    def __init__(self, N, N_THETA, N_RHO, N_ITER, BETA=1., SYS_MAT_FILE=PATH_SYSTEM_MATRIX):\n",
    "        super(QNM_RNN, self).__init__()\n",
    "\n",
    "        self.N = N\n",
    "        self.N_THETA = N_THETA\n",
    "        self.N_RHO = N_RHO\n",
    "        self.N_ITER = N_ITER\n",
    "        self.BETA = BETA\n",
    "        self.sys_mat_dir = PATH_SYSTEM_MATRIX\n",
    "\n",
    "        self.qnm_rnn_cells = nn.ModuleList([QNM_RNNCell(N=self.N, N_THETA=self.N_THETA, N_RHO=self.N_RHO) for _ in range(self.N_ITER)])\n",
    "\n",
    "        self.A = self.__init_system_matrix__() \n",
    "\n",
    "\n",
    "    def __init_system_matrix__(self):\n",
    "        print(\"__BEGIN__Loading the system matrix__\")\n",
    "        with open(self.sys_mat_dir, 'rb') as f:\n",
    "            A = torch.Tensor(np.load(f))\n",
    "            A.requires_grad = False\n",
    "        print(\"__DONE__Loading the system matrix__\")\n",
    "\n",
    "        return A\n",
    "\n",
    "\n",
    "    def forward(self, y):\n",
    "        tot_h_loss = 0\n",
    "\n",
    "        H_t = self.BETA * torch.eye(self.N).type_as(y)\n",
    "        sigmaE_t = torch.zeros((self.N, self.N)).type_as(y)\n",
    "\n",
    "        y = torch.reshape(y, (self.N_RHO*self.N_THETA, ))\n",
    "        \n",
    "        x_t = torch.zeros((self.N, self.N)).type_as(y)\n",
    "        x_t = x_t[None, None, :, :]\n",
    "        \n",
    "        self.A = self.A.type_as(y)\n",
    "        As = self.A.to_sparse()\n",
    "        \n",
    "        for qnm_model in self.qnm_rnn_cells:\n",
    "            x_t, H_t, sigmaE_t, h_t_loss = qnm_model(As, x_t, y, H_t, sigmaE_t)\n",
    "            tot_h_loss += h_t_loss\n",
    "        \n",
    "        return x_t, (tot_h_loss/self.N_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dmIpKMWGygMi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmIpKMWGygMi",
    "outputId": "2e683ba0-15c5-4716-b8bc-6c8ca2bdc3ee"
   },
   "outputs": [],
   "source": [
    "qnm_model = QNM_RNN(N=IMG_SIZE, N_THETA=N_THETA, N_RHO=N_RHO, N_ITER=N_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pl0VoadM-Nzv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pl0VoadM-Nzv",
    "outputId": "01527eb0-c08b-484c-8056-09f8101c1588"
   },
   "outputs": [],
   "source": [
    "for name, parameter in qnm_model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aMZseWaI0b0O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "aMZseWaI0b0O",
    "outputId": "5e544834-e374-4e9d-95d5-d9e64c10b738"
   },
   "outputs": [],
   "source": [
    "x_out, h_loss = qnm_model(inp.cuda())\n",
    "print(h_loss)\n",
    "plt.imshow(np.squeeze(x_out.cpu().detach()), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vg-5gYw-mGEs",
   "metadata": {
    "id": "vg-5gYw-mGEs"
   },
   "source": [
    "# **Lightning GAN architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Gvm0fdH-tV66",
   "metadata": {
    "id": "Gvm0fdH-tV66"
   },
   "outputs": [],
   "source": [
    "class LQNM(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        N_ITER, \n",
    "        N, \n",
    "        N_THETA, \n",
    "        N_RHO,\n",
    "        BETA=1., \n",
    "        lr: float = 0.0002,\n",
    "        b1: float = 0.5,\n",
    "        b2: float = 0.999,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(LQNM, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.automatic_optimization = False\n",
    "        \n",
    "        self.train_step_idx = 0\n",
    "\n",
    "        self.qnm_model = QNM_RNN(N=N, N_THETA=N_THETA, N_RHO=N_RHO, N_ITER=N_ITER, BETA=BETA)\n",
    "\n",
    "        \n",
    "    def __train_step_idx__(self):\n",
    "        return self.train_step_idx\n",
    "        \n",
    "\n",
    "    def forward(self, y):\n",
    "        return self.qnm_model(y)\n",
    "\n",
    "    \n",
    "    def QNM_loss(self, rec_img, tar_img):\n",
    "        l1_loss = nn.L1Loss()\n",
    "        \n",
    "        mae_loss = l1_loss(rec_img, tar_img)\n",
    "        s_loss = ssim_loss(rec_img, tar_img, 5)\n",
    "        \n",
    "        total_loss = mae_loss + s_loss\n",
    "\n",
    "        return total_loss    \n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        opt_qnm = self.optimizers()\n",
    "        \n",
    "        y, tar_img, angle, step = batch\n",
    "\n",
    "        rec_img, h_loss = self(y)\n",
    "\n",
    "        ######################\n",
    "        # Optimize QNM-RNN   #\n",
    "        ######################\n",
    "        # compute losses\n",
    "        qnm_loss = self.QNM_loss(rec_img, tar_img) + h_loss\n",
    "            \n",
    "        opt_qnm.zero_grad()\n",
    "        self.manual_backward(qnm_loss)\n",
    "        opt_qnm.step()\n",
    "        \n",
    "        self.train_step_idx += 1\n",
    "        self.log_dict({\"QNM-RNN_loss\": qnm_loss}, prog_bar=True) \n",
    "\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y, tar_img, _, _ = batch\n",
    "\n",
    "        rec_img, h_loss = self.qnm_model(y)\n",
    "        val_qnm_loss = self.QNM_loss(rec_img, tar_img) + h_loss\n",
    "\n",
    "        self.log_dict({\"val_qnm_loss\": val_qnm_loss}, prog_bar=True)\n",
    "  \n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # check if the saving dir exist else create it\n",
    "        if not os.path.exists(SAVE_TEST):\n",
    "            os.makedirs(SAVE_TEST)\n",
    "        \n",
    "        y, tar_img, angle, step = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            rec_img, h_loss = self.forward(y)\n",
    "            self.train()\n",
    "            val_qnm_loss = self.QNM_loss(rec_img, tar_img) + h_loss\n",
    "            \n",
    "            self.log_dict({\"val_qnm_loss\": val_qnm_loss}, prog_bar=True)\n",
    "            \n",
    "            psnr_p = -psnr_loss(tar_img, rec_img, 1).cpu()\n",
    "            ssim_p = (-2 * ssim_loss(tar_img, rec_img, 5) + 1).cpu()\n",
    "            file = (SAVE_TEST+\"idx_\"+str(batch_idx)+\"_angle=\"+str(angle.cpu().numpy())+\"_step=\"+str(step.cpu().numpy())\n",
    "                             +\"_psnr=\"+str(psnr_p.numpy())+\"_ssim=\"+str(ssim_p.numpy())+\".png\")\n",
    "            save_image(rec_img, file)\n",
    "            display_list = [angle, step, y, tar_img, rec_img]\n",
    "            display_func(display_list)     \n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "        \n",
    "        opt_qnm = torch.optim.Adam(self.qnm_model.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "        return opt_qnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ZKcwTuVG1i5z",
   "metadata": {
    "id": "ZKcwTuVG1i5z"
   },
   "outputs": [],
   "source": [
    "class DisplayCallback(Callback):\n",
    "    def __init__(self, every_n_steps=500):\n",
    "        super().__init__()\n",
    "        self.every_n_steps = every_n_steps\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, *args):\n",
    "        val_dataloader = trainer.val_dataloaders[0]\n",
    "        val_dataset = val_dataloader.dataset\n",
    "\n",
    "        y, tar_img, angle, step = next(iter(val_dataset))\n",
    "        \n",
    "        if pl_module.__train_step_idx__() % self.every_n_steps == 0:\n",
    "            # Reconstruct images\n",
    "            y = y.to(pl_module.device)\n",
    "            y = y[None, :, :, :]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pl_module.eval()\n",
    "                rec_img, _= pl_module(y)\n",
    "                pl_module.train()\n",
    "                \n",
    "                display_list = [angle, step, y, tar_img[None, :, :, :], rec_img]\n",
    "                display_func(display_list)\n",
    "                \n",
    "    def on_train_epoch_end(self, trainer, pl_module, *args):\n",
    "        if not os.path.exists(SAVE_VALID):\n",
    "            os.makedirs(SAVE_VALID)\n",
    "            \n",
    "        val_dataloader = trainer.val_dataloaders[0]\n",
    "        val_dataset = val_dataloader.dataset\n",
    "\n",
    "        y, tar_img, angle, step = next(iter(val_dataset))\n",
    "        \n",
    "        # Reconstruct images\n",
    "        y = y.to(pl_module.device)\n",
    "        y = y[None, :, :, :]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pl_module.eval()\n",
    "            rec_img, _= pl_module(y)\n",
    "            pl_module.train()\n",
    "                \n",
    "            display_list = [angle, step, y, tar_img[None, :, :, :], rec_img]\n",
    "            display_func(display_list, save=True, epoch=trainer.current_epoch)                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NczSl_44fsRB",
   "metadata": {
    "id": "NczSl_44fsRB"
   },
   "source": [
    "# **Traing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wz727qM-uBjM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "59a46fc7a1264f37adbd8b2daea22a16",
      "6496622cca03413b9ea2f3aa3e1906d0",
      "b631c533f64e49bb97af043f230938b3",
      "513f95655703409f83fc5aeeead527b9",
      "463d9469cedc450f85cf5797bb96fa59",
      "ba0b67e55cff46e4873cb26f204cd64e",
      "61dd9be965d94a35971cc3c46111d215",
      "744681a00e1347aeb65f3caa36b1211a",
      "ea5617e559aa42fb81d7aa1a9b584dcb",
      "1837b5f3ed7f45d1be27516a457894ea",
      "8239b7124d3a46fcb166e6300b58f764",
      "4602002682d74c69bcd9f3a50fb9d7f9",
      "c18f79eb6d93407bb24e1ddc506faf8d",
      "4f42fb1b368e449d9f85ba26a6d9b2cb",
      "01ec595e74d94be1992dfa30e883c455",
      "9a943476bc1d41c28d586a5a4183649a",
      "148a4f27ee7a4f958b837119b64d768c",
      "c7067ac0a89740a29719a6d456ef8c5e",
      "f75c79d1cecb4aaa9808fb7d3d0e217f",
      "46f4947024b941afa19843cdb77f8207",
      "df639726264d4ac19e11e2b816795d2d",
      "7abb21e45e4949a2befd462f9869a3b7"
     ]
    },
    "id": "wz727qM-uBjM",
    "outputId": "53434941-3431-4d1d-a597-2b4e2d497231"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__BEGIN__Loading the system matrix__\n"
     ]
    }
   ],
   "source": [
    "ct_data = CTDataModule()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_weights_only=True,\n",
    "    dirpath = CHECKPOINT_PATH,\n",
    "    monitor=\"val_qnm_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    strategy=\"dp\",\n",
    "    gpus=AVAIL_GPUS,\n",
    "    max_epochs=10, \n",
    "    callbacks=[\n",
    "               checkpoint_callback,\n",
    "               DisplayCallback(every_n_steps=2000),\n",
    "               LearningRateMonitor(\"epoch\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "pretrained_filename = CHECKPOINT_PATH\n",
    "ckpt_found = False\n",
    "for x in os.listdir(pretrained_filename):\n",
    "    if x.endswith(\".ckpt\"):\n",
    "        ckpt_found = True\n",
    "        pretrained_filename += x\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        break\n",
    "\n",
    "if ckpt_found:\n",
    "    model = LQNM.load_from_checkpoint(pretrained_filename)\n",
    "else :\n",
    "    model = LQNM(N_ITER=N_ITER, N=IMG_SIZE, N_THETA=N_THETA, N_RHO=N_RHO)\n",
    "    trainer.fit(model, ct_data)\n",
    "    \n",
    "trainer.test(model, ct_data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Learned_Quasi_Newton_Method.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01ec595e74d94be1992dfa30e883c455": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df639726264d4ac19e11e2b816795d2d",
      "placeholder": "​",
      "style": "IPY_MODEL_7abb21e45e4949a2befd462f9869a3b7",
      "value": " 720/10789 [04:22&lt;1:01:08,  2.74it/s, v_num=16, QNM-RNN_loss=148.0]"
     }
    },
    "148a4f27ee7a4f958b837119b64d768c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1837b5f3ed7f45d1be27516a457894ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4602002682d74c69bcd9f3a50fb9d7f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c18f79eb6d93407bb24e1ddc506faf8d",
       "IPY_MODEL_4f42fb1b368e449d9f85ba26a6d9b2cb",
       "IPY_MODEL_01ec595e74d94be1992dfa30e883c455"
      ],
      "layout": "IPY_MODEL_9a943476bc1d41c28d586a5a4183649a"
     }
    },
    "463d9469cedc450f85cf5797bb96fa59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "46f4947024b941afa19843cdb77f8207": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f42fb1b368e449d9f85ba26a6d9b2cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f75c79d1cecb4aaa9808fb7d3d0e217f",
      "max": 10789,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46f4947024b941afa19843cdb77f8207",
      "value": 720
     }
    },
    "513f95655703409f83fc5aeeead527b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1837b5f3ed7f45d1be27516a457894ea",
      "placeholder": "​",
      "style": "IPY_MODEL_8239b7124d3a46fcb166e6300b58f764",
      "value": " 2/2 [00:00&lt;00:00,  2.97it/s]"
     }
    },
    "59a46fc7a1264f37adbd8b2daea22a16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6496622cca03413b9ea2f3aa3e1906d0",
       "IPY_MODEL_b631c533f64e49bb97af043f230938b3",
       "IPY_MODEL_513f95655703409f83fc5aeeead527b9"
      ],
      "layout": "IPY_MODEL_463d9469cedc450f85cf5797bb96fa59"
     }
    },
    "61dd9be965d94a35971cc3c46111d215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6496622cca03413b9ea2f3aa3e1906d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba0b67e55cff46e4873cb26f204cd64e",
      "placeholder": "​",
      "style": "IPY_MODEL_61dd9be965d94a35971cc3c46111d215",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "744681a00e1347aeb65f3caa36b1211a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7abb21e45e4949a2befd462f9869a3b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8239b7124d3a46fcb166e6300b58f764": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a943476bc1d41c28d586a5a4183649a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "b631c533f64e49bb97af043f230938b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_744681a00e1347aeb65f3caa36b1211a",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ea5617e559aa42fb81d7aa1a9b584dcb",
      "value": 2
     }
    },
    "ba0b67e55cff46e4873cb26f204cd64e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f79eb6d93407bb24e1ddc506faf8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_148a4f27ee7a4f958b837119b64d768c",
      "placeholder": "​",
      "style": "IPY_MODEL_c7067ac0a89740a29719a6d456ef8c5e",
      "value": "Epoch 0:   7%"
     }
    },
    "c7067ac0a89740a29719a6d456ef8c5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df639726264d4ac19e11e2b816795d2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea5617e559aa42fb81d7aa1a9b584dcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f75c79d1cecb4aaa9808fb7d3d0e217f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
